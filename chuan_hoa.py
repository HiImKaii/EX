import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
import os
import warnings
warnings.filterwarnings('ignore')

class CSVDataNormalizer:
    def __init__(self, file_path):
        """Kh·ªüi t·∫°o v·ªõi ƒë∆∞·ªùng d·∫´n file CSV"""
        self.file_path = file_path
        self.df = None
        self.original_df = None  # L∆∞u b·∫£n g·ªëc ƒë·ªÉ so s√°nh
        self.flood_column = None
        self.processing_columns = []
        
    def load_data(self):
        """T·∫£i d·ªØ li·ªáu t·ª´ file CSV"""
        try:
            encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']
            
            for encoding in encodings:
                try:
                    self.df = pd.read_csv(self.file_path, encoding=encoding)
                    self.original_df = self.df.copy()  # L∆∞u b·∫£n g·ªëc
                    print(f"‚úÖ ƒê·ªçc file th√†nh c√¥ng: {self.df.shape[0]} h√†ng, {self.df.shape[1]} c·ªôt")
                    break
                except UnicodeDecodeError:
                    continue
            
            if self.df is None:
                raise Exception("Kh√¥ng th·ªÉ ƒë·ªçc file v·ªõi b·∫•t k·ª≥ encoding n√†o")
            
            self._identify_columns()
            return True
            
        except Exception as e:
            print(f"‚ùå L·ªói: {str(e)}")
            return False
    
    def _identify_columns(self):
        """X√°c ƒë·ªãnh c√°c c·ªôt c·∫ßn x·ª≠ l√Ω"""
        columns = list(self.df.columns)
        print(f"\nüìã Danh s√°ch t·∫•t c·∫£ c√°c c·ªôt: {columns}")
        
        if len(columns) >= 1:
            self.flood_column = columns[0]
            self.processing_columns = columns[1:]  # T·∫•t c·∫£ c√°c c·ªôt tr·ª´ c·ªôt flood
        else:
            print("‚ö†Ô∏è File ph·∫£i c√≥ √≠t nh·∫•t 1 c·ªôt!")
            return
        
        print(f"üåä C·ªôt nh√£n l≈© (kh√¥ng x·ª≠ l√Ω): {self.flood_column}")
        print(f"üîß C√°c c·ªôt c·∫ßn x·ª≠ l√Ω ({len(self.processing_columns)}): {self.processing_columns}")
        
        # Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt v·ªÅ t·ª´ng c·ªôt
        print(f"\nüìä Th√¥ng tin chi ti·∫øt t·ª´ng c·ªôt:")
        for i, col in enumerate(self.processing_columns):
            dtype = self.df[col].dtype
            null_count = self.df[col].isnull().sum()
            unique_count = self.df[col].nunique()
            print(f"  {i+1:2d}. {col:20s} | Ki·ªÉu: {str(dtype):10s} | Null: {null_count:4d} | Unique: {unique_count:4d}")
    
    def show_column_statistics(self, col_name):
        """Hi·ªÉn th·ªã th·ªëng k√™ c·ªßa m·ªôt c·ªôt"""
        if col_name not in self.df.columns:
            print(f"‚ùå C·ªôt '{col_name}' kh√¥ng t·ªìn t·∫°i")
            return
        
        print(f"\nüìà Th·ªëng k√™ c·ªôt '{col_name}':")
        print(f"  Ki·ªÉu d·ªØ li·ªáu: {self.df[col_name].dtype}")
        print(f"  S·ªë gi√° tr·ªã null: {self.df[col_name].isnull().sum()}")
        print(f"  S·ªë gi√° tr·ªã unique: {self.df[col_name].nunique()}")
        
        if pd.api.types.is_numeric_dtype(self.df[col_name]):
            stats = self.df[col_name].describe()
            print(f"  Min: {stats['min']:.4f}")
            print(f"  Max: {stats['max']:.4f}")
            print(f"  Mean: {stats['mean']:.4f}")
            print(f"  Std: {stats['std']:.4f}")
        else:
            print(f"  Top values: {dict(self.df[col_name].value_counts().head(3))}")
    
    def handle_missing_values_for_column(self, col_name):
        """X·ª≠ l√Ω gi√° tr·ªã thi·∫øu cho m·ªôt c·ªôt c·ª• th·ªÉ"""
        if col_name not in self.processing_columns:
            print(f"‚ùå C·ªôt '{col_name}' kh√¥ng trong danh s√°ch x·ª≠ l√Ω")
            return False
        
        null_count = self.df[col_name].isnull().sum()
        if null_count == 0:
            print(f"‚úÖ C·ªôt '{col_name}': Kh√¥ng c√≥ gi√° tr·ªã thi·∫øu")
            return True
        
        print(f"üîß X·ª≠ l√Ω {null_count} gi√° tr·ªã thi·∫øu trong c·ªôt '{col_name}'")
        
        if pd.api.types.is_numeric_dtype(self.df[col_name]):
            # C·ªôt s·ªë: ƒëi·ªÅn b·∫±ng mean
            mean_val = self.df[col_name].mean()
            self.df[col_name].fillna(mean_val, inplace=True)
            print(f"  ‚û§ ƒêi·ªÅn b·∫±ng mean: {mean_val:.4f}")
        else:
            # C·ªôt ph√¢n lo·∫°i: ƒëi·ªÅn b·∫±ng mode
            mode_val = self.df[col_name].mode()[0] if not self.df[col_name].mode().empty else 'Unknown'
            self.df[col_name].fillna(mode_val, inplace=True)
            print(f"  ‚û§ ƒêi·ªÅn b·∫±ng mode: '{mode_val}'")
        
        return True
    
    def normalize_numeric_column(self, col_name, method='minmax'):
        """Chu·∫©n h√≥a m·ªôt c·ªôt s·ªë v·ªÅ kho·∫£ng [0,1]"""
        if col_name not in self.processing_columns:
            print(f"‚ùå C·ªôt '{col_name}' kh√¥ng trong danh s√°ch x·ª≠ l√Ω")
            return False
        
        if not pd.api.types.is_numeric_dtype(self.df[col_name]):
            print(f"‚ö†Ô∏è C·ªôt '{col_name}' kh√¥ng ph·∫£i l√† s·ªë - b·ªè qua chu·∫©n h√≥a")
            return False
        
        original_stats = {
            'min': self.df[col_name].min(),
            'max': self.df[col_name].max(),
            'mean': self.df[col_name].mean(),
            'std': self.df[col_name].std()
        }
        
        print(f"üéØ Chu·∫©n h√≥a c·ªôt '{col_name}' b·∫±ng ph∆∞∆°ng ph√°p '{method}'")
        print(f"  Tr∆∞·ªõc: min={original_stats['min']:.4f}, max={original_stats['max']:.4f}")
        
        if method == 'minmax':
            # Min-Max: (x - min) / (max - min) -> [0, 1]
            min_val = self.df[col_name].min()
            max_val = self.df[col_name].max()
            if max_val != min_val:
                self.df[col_name] = (self.df[col_name] - min_val) / (max_val - min_val)
            else:
                print(f"  ‚ö†Ô∏è T·∫•t c·∫£ gi√° tr·ªã ƒë·ªÅu b·∫±ng nhau: {min_val}")
                self.df[col_name] = 0  # G√°n v·ªÅ 0 n·∫øu t·∫•t c·∫£ gi√° tr·ªã gi·ªëng nhau
                
        elif method == 'standard':
            # Z-score: (x - mean) / std, sau ƒë√≥ √°p d·ª•ng sigmoid ƒë·ªÉ ƒë∆∞a v·ªÅ [0,1]
            mean_val = self.df[col_name].mean()
            std_val = self.df[col_name].std()
            if std_val != 0:
                z_scores = (self.df[col_name] - mean_val) / std_val
                # √Åp d·ª•ng sigmoid: 1 / (1 + exp(-z))
                self.df[col_name] = 1 / (1 + np.exp(-z_scores))
            else:
                self.df[col_name] = 0.5  # G√°n v·ªÅ 0.5 n·∫øu std = 0
        
        new_stats = {
            'min': self.df[col_name].min(),
            'max': self.df[col_name].max(),
            'mean': self.df[col_name].mean()
        }
        
        print(f"  Sau:  min={new_stats['min']:.4f}, max={new_stats['max']:.4f}, mean={new_stats['mean']:.4f}")
        return True
    
    def encode_categorical_column(self, col_name):
        """M√£ h√≥a m·ªôt c·ªôt ph√¢n lo·∫°i th√†nh s·ªë trong kho·∫£ng [0,1]"""
        if col_name not in self.processing_columns:
            print(f"‚ùå C·ªôt '{col_name}' kh√¥ng trong danh s√°ch x·ª≠ l√Ω")
            return False
        
        if pd.api.types.is_numeric_dtype(self.df[col_name]):
            print(f"‚ö†Ô∏è C·ªôt '{col_name}' ƒë√£ l√† s·ªë - b·ªè qua m√£ h√≥a")
            return False
        
        print(f"üè∑Ô∏è M√£ h√≥a c·ªôt ph√¢n lo·∫°i '{col_name}'")
        unique_vals = self.df[col_name].nunique()
        print(f"  S·ªë l∆∞·ª£ng nh√≥m: {unique_vals}")
        
        # X·ª≠ l√Ω NaN tr∆∞·ªõc khi m√£ h√≥a
        if self.df[col_name].isnull().any():
            self.df[col_name] = self.df[col_name].fillna('__MISSING__')
        
        # M√£ h√≥a b·∫±ng LabelEncoder
        le = LabelEncoder()
        encoded_values = le.fit_transform(self.df[col_name])
        
        # Chu·∫©n h√≥a v·ªÅ [0,1] n·∫øu c√≥ nhi·ªÅu h∆°n 1 nh√≥m
        if len(le.classes_) > 1:
            encoded_values = encoded_values / (len(le.classes_) - 1)
        else:
            encoded_values = np.zeros_like(encoded_values)
        
        self.df[col_name] = encoded_values
        
        print(f"  √Ånh x·∫°: {dict(zip(le.classes_, np.unique(encoded_values)))}")
        return True
    
    def process_column(self, col_name, normalization_method='minmax'):
        """X·ª≠ l√Ω ho√†n ch·ªânh m·ªôt c·ªôt: missing values + chu·∫©n h√≥a/m√£ h√≥a"""
        print(f"\n{'='*60}")
        print(f"üîÑ X·ª¨ L√ù C·ªòT: '{col_name}'")
        print(f"{'='*60}")
        
        # Hi·ªÉn th·ªã th·ªëng k√™ ban ƒë·∫ßu
        self.show_column_statistics(col_name)
        
        # X·ª≠ l√Ω gi√° tr·ªã thi·∫øu
        if not self.handle_missing_values_for_column(col_name):
            return False
        
        # Chu·∫©n h√≥a ho·∫∑c m√£ h√≥a
        if pd.api.types.is_numeric_dtype(self.df[col_name]):
            success = self.normalize_numeric_column(col_name, normalization_method)
        else:
            success = self.encode_categorical_column(col_name)
        
        if success:
            print(f"‚úÖ Ho√†n th√†nh x·ª≠ l√Ω c·ªôt '{col_name}'")
        
        return success
    
    def is_column_normalized(self, col_name):
        """Ki·ªÉm tra xem m·ªôt c·ªôt ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a hay ch∆∞a"""
        if not pd.api.types.is_numeric_dtype(self.df[col_name]):
            return False
        
        min_val = self.df[col_name].min()
        max_val = self.df[col_name].max()
        
        # Ki·ªÉm tra xem gi√° tr·ªã c√≥ n·∫±m trong kho·∫£ng [0,1] kh√¥ng
        return (min_val >= -1e-10) and (max_val <= 1 + 1e-10)
    
    def process_all_columns(self, normalization_method='minmax'):
        """X·ª≠ l√Ω t·∫•t c·∫£ c√°c c·ªôt ch∆∞a ƒë∆∞·ª£c chu·∫©n h√≥a (tr·ª´ c·ªôt flood)"""
        print("üöÄ B·∫ÆT ƒê·∫¶U KI·ªÇM TRA V√Ä X·ª¨ L√ù C√ÅC C·ªòT")
        print("=" * 80)
        
        if not self.processing_columns:
            print("‚ö†Ô∏è Kh√¥ng c√≥ c·ªôt n√†o ƒë·ªÉ x·ª≠ l√Ω")
            return False
        
        columns_to_process = []
        for col in self.processing_columns:
            if not self.is_column_normalized(col):
                columns_to_process.append(col)
                
        if not columns_to_process:
            print("‚úÖ T·∫•t c·∫£ c√°c c·ªôt ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a")
            return True
            
        print(f"\nüéØ Ph√°t hi·ªán {len(columns_to_process)} c·ªôt c·∫ßn chu·∫©n h√≥a:")
        for col in columns_to_process:
            print(f"  - {col}")
        
        success_count = 0
        for i, col in enumerate(columns_to_process):
            print(f"\n[{i+1}/{len(columns_to_process)}] ƒêang x·ª≠ l√Ω c·ªôt: {col}")
            if self.process_column(col, normalization_method):
                success_count += 1
        
        print(f"\nüìä K·∫æT QU·∫¢ T·ªîNG QUAN:")
        print(f"  T·ªïng s·ªë c·ªôt c·∫ßn x·ª≠ l√Ω: {len(columns_to_process)}")
        print(f"  X·ª≠ l√Ω th√†nh c√¥ng: {success_count}")
        print(f"  X·ª≠ l√Ω th·∫•t b·∫°i: {len(columns_to_process) - success_count}")
        
        return success_count == len(columns_to_process)
    
    def save_data(self, suffix="_normalized"):
        """L∆∞u d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω"""
        base_name = os.path.splitext(self.file_path)[0]
        output_path = f"{base_name}{suffix}.csv"
        
        try:
            self.df.to_csv(output_path, index=False, encoding='utf-8')
            print(f"üíæ ƒê√£ l∆∞u file: {output_path}")
            print(f"üìè K√≠ch th∆∞·ªõc: {self.df.shape[0]} h√†ng x {self.df.shape[1]} c·ªôt")
            return output_path
        except Exception as e:
            print(f"‚ùå L·ªói l∆∞u file: {str(e)}")
            return None
    
    def show_comparison(self, col_name, sample_size=10):
        """So s√°nh d·ªØ li·ªáu tr∆∞·ªõc v√† sau x·ª≠ l√Ω"""
        if col_name not in self.df.columns:
            print(f"‚ùå C·ªôt '{col_name}' kh√¥ng t·ªìn t·∫°i")
            return
        
        print(f"\nüîç SO S√ÅNH D·ªÆ LI·ªÜU C·ªòT '{col_name}':")
        comparison_df = pd.DataFrame({
            'Tr∆∞·ªõc': self.original_df[col_name].head(sample_size),
            'Sau': self.df[col_name].head(sample_size)
        })
        print(comparison_df)

# Ch∆∞∆°ng tr√¨nh ch√≠nh
if __name__ == "__main__":
    # ƒê∆∞·ªùng d·∫´n file CSV
    file_path = r"C:\Users\Admin\Downloads\prj\Flood_point\merged_flood_point_merge_cleaned_balanced_reordered_nonlatlon.csv"
    
    # Kh·ªüi t·∫°o normalizer
    normalizer = CSVDataNormalizer(file_path)
    
    # T·∫£i d·ªØ li·ªáu
    if normalizer.load_data():
        print("\n" + "="*80)
        print("üéõÔ∏è T·ª∞ ƒê·ªòNG X·ª¨ L√ù T·∫§T C·∫¢ C√ÅC C·ªòT")
        print("=" * 80)
        
        # T·ª± ƒë·ªông x·ª≠ l√Ω t·∫•t c·∫£ c√°c c·ªôt v·ªõi ph∆∞∆°ng ph√°p minmax
        success = normalizer.process_all_columns(normalization_method='minmax')
        
        if success:
            # T·ª± ƒë·ªông l∆∞u k·∫øt qu·∫£
            output_path = normalizer.save_data()
            if output_path:
                print(f"\n‚úÖ HO√ÄN TH√ÄNH TH√ÄNH C√îNG!")
                print(f"üìÅ File ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {output_path}")
                print(f"üìä D·ªØ li·ªáu cu·ªëi c√πng: {normalizer.df.shape[0]} h√†ng x {normalizer.df.shape[1]} c·ªôt")
                
                # Hi·ªÉn th·ªã th·ªëng k√™ t·ªïng quan
                print(f"\nüìà TH·ªêNG K√ä T·ªîNG QUAN:")
                print(f"  - C·ªôt nh√£n l≈© (gi·ªØ nguy√™n): {normalizer.flood_column}")
                print(f"  - C·ªôt LULC (gi·ªØ nguy√™n): {normalizer.lulc_column}")
                print(f"  - S·ªë c·ªôt ƒë√£ chu·∫©n h√≥a: {len(normalizer.processing_columns)}")
                
                # Hi·ªÉn th·ªã kho·∫£ng gi√° tr·ªã c·ªßa c√°c c·ªôt ƒë√£ x·ª≠ l√Ω
                print(f"\nüéØ KHO·∫¢NG GI√Å TR·ªä SAU CHU·∫®N H√ìA:")
                for col in normalizer.processing_columns[:5]:  # Hi·ªÉn th·ªã 5 c·ªôt ƒë·∫ßu
                    min_val = normalizer.df[col].min()
                    max_val = normalizer.df[col].max()
                    print(f"  {col}: [{min_val:.6f}, {max_val:.6f}]")
                if len(normalizer.processing_columns) > 5:
                    print(f"  ... v√† {len(normalizer.processing_columns) - 5} c·ªôt kh√°c")
            else:
                print("‚ùå C√≥ l·ªói khi l∆∞u file!")
        else:
            print("‚ùå C√≥ l·ªói trong qu√° tr√¨nh x·ª≠ l√Ω!")
    else:
        print("‚ùå Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu!")
    
    print("\nüëã Ch∆∞∆°ng tr√¨nh k·∫øt th√∫c!")