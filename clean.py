import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

def filter_and_prepare_data(input_file, output_file, sample_size=10000, random_state=42):
    """
    Lá»c dá»¯ liá»‡u tá»« file gá»‘c Ä‘á»ƒ táº¡o file nhá» vá»›i cÃ¡c Ä‘áº·c trÆ°ng Ä‘Ã£ chá»n
    vÃ  cÃ¢n báº±ng máº«u giá»¯a lÅ© vÃ  khÃ´ng lÅ©
    """
    
    print("ğŸ”„ Äang táº£i dá»¯ liá»‡u...")
    # Äá»c dá»¯ liá»‡u
    df = pd.read_csv(input_file)
    print(f"âœ… ÄÃ£ táº£i: {len(df)} Ä‘iá»ƒm dá»¯ liá»‡u")
    
    # CÃ¡c Ä‘áº·c trÆ°ng cáº§n giá»¯ (Ä‘Ã£ chá»n tá»« phÃ¢n tÃ­ch tÆ°Æ¡ng quan)
    features_to_keep = [
        'dem', 'slope', 'twi', 
        'avg_NDVI', 'avg_NDBI', 'std_NDWI',
        'Density_River', 'Density_Road',
        'Distan2river_met', 'Distan2road_met'
    ]
    
    # CÃ¡c cá»™t lÅ© cáº§n gá»™p
    flood_columns = [col for col in df.columns if 'floodevent' in col]
    print(f"ğŸŒŠ TÃ¬m tháº¥y {len(flood_columns)} cá»™t lÅ©: {flood_columns}")
    
    # TÃ­nh toÃ¡n cÃ¡c Ä‘áº·c trÆ°ng trung bÃ¬nh vÃ  Ä‘á»™ lá»‡ch chuáº©n
    print("ğŸ“Š Äang tÃ­nh toÃ¡n cÃ¡c Ä‘áº·c trÆ°ng phá»•...")
    
    # TÃ­nh trung bÃ¬nh vÃ  Ä‘á»™ lá»‡ch chuáº©n cho cÃ¡c chá»‰ sá»‘ phá»•
    for index in ['NDVI', 'NDBI', 'NDWI']:
        year_cols = [col for col in df.columns if index in col and any(year in col for year in ['2020', '2021', '2022', '2023', '2024'])]
        if year_cols:
            df[f'avg_{index}'] = df[year_cols].mean(axis=1, skipna=True)
            df[f'std_{index}'] = df[year_cols].std(axis=1, skipna=True)
    
    # Táº¡o cá»™t lÅ© nhá»‹ phÃ¢n (1 náº¿u cÃ³ Ã­t nháº¥t 1 láº§n lÅ©, 0 náº¿u khÃ´ng)
    print("â›ˆï¸ Äang gá»™p cÃ¡c cá»™t lÅ©...")
    df['flood_event'] = (df[flood_columns].sum(axis=1) > 0).astype(int)
    
    # Kiá»ƒm tra phÃ¢n bá»‘ lÅ©
    flood_count = df['flood_event'].sum()
    no_flood_count = len(df) - flood_count
    print(f"ğŸ“Š PhÃ¢n bá»‘ lÅ©: {flood_count} Ä‘iá»ƒm cÃ³ lÅ© ({flood_count/len(df)*100:.1f}%), {no_flood_count} Ä‘iá»ƒm khÃ´ng lÅ© ({no_flood_count/len(df)*100:.1f}%)")
    
    # Kiá»ƒm tra cÃ¡c Ä‘áº·c trÆ°ng cáº§n giá»¯ cÃ³ tá»“n táº¡i khÃ´ng
    available_features = [col for col in features_to_keep if col in df.columns]
    missing_features = [col for col in features_to_keep if col not in df.columns]
    
    if missing_features:
        print(f"âš ï¸ Cáº£nh bÃ¡o: Thiáº¿u cÃ¡c Ä‘áº·c trÆ°ng: {missing_features}")
        print(f"âœ… Sáº½ sá»­ dá»¥ng cÃ¡c Ä‘áº·c trÆ°ng cÃ³ sáºµn: {available_features}")
    
    # Loáº¡i bá» cÃ¡c hÃ ng cÃ³ giÃ¡ trá»‹ NaN trong cÃ¡c Ä‘áº·c trÆ°ng cáº§n thiáº¿t
    clean_data = df[available_features + ['flood_event']].dropna()
    print(f"ğŸ§¹ Sau khi loáº¡i bá» NaN: {len(clean_data)} Ä‘iá»ƒm dá»¯ liá»‡u")
    
    # PhÃ¢n tÃ¡ch dá»¯ liá»‡u lÅ© vÃ  khÃ´ng lÅ©
    flood_data = clean_data[clean_data['flood_event'] == 1]
    no_flood_data = clean_data[clean_data['flood_event'] == 0]
    
    print(f"ğŸ“Š Sau khi lÃ m sáº¡ch:")
    print(f"   - CÃ³ lÅ©: {len(flood_data)} Ä‘iá»ƒm")
    print(f"   - KhÃ´ng lÅ©: {len(no_flood_data)} Ä‘iá»ƒm")
    
    # TÃ­nh sá»‘ lÆ°á»£ng máº«u cho má»—i lá»›p (50% lÅ©, 50% khÃ´ng lÅ©)
    samples_per_class = sample_size // 2
    
    # Láº¥y máº«u tá»« má»—i lá»›p
    if len(flood_data) >= samples_per_class and len(no_flood_data) >= samples_per_class:
        # Láº¥y máº«u ngáº«u nhiÃªn tá»« má»—i lá»›p
        sampled_flood = flood_data.sample(n=samples_per_class, random_state=random_state)
        sampled_no_flood = no_flood_data.sample(n=samples_per_class, random_state=random_state)
        
        # Káº¿t há»£p hai máº«u
        final_sample = pd.concat([sampled_flood, sampled_no_flood])
        
        # XÃ¡o trá»™n dá»¯ liá»‡u
        final_sample = final_sample.sample(frac=1, random_state=random_state).reset_index(drop=True)
        
        print(f"ğŸ¯ ÄÃ£ láº¥y máº«u cÃ¢n báº±ng: {len(final_sample)} Ä‘iá»ƒm (50% lÅ©, 50% khÃ´ng lÅ©)")
        
    else:
        print("âš ï¸ Dá»¯ liá»‡u khÃ´ng Ä‘á»§ Ä‘á»ƒ láº¥y máº«u cÃ¢n báº±ng theo yÃªu cáº§u")
        print("ğŸ’¡ Sáº½ láº¥y máº«u tá»‘i Ä‘a cÃ³ thá»ƒ vá»›i tá»· lá»‡ cÃ¢n báº±ng")
        
        min_class_size = min(len(flood_data), len(no_flood_data))
        if min_class_size > 0:
            sampled_flood = flood_data.sample(n=min(min_class_size, sample_size//2), random_state=random_state)
            sampled_no_flood = no_flood_data.sample(n=min(min_class_size, sample_size//2), random_state=random_state)
            final_sample = pd.concat([sampled_flood, sampled_no_flood])
            final_sample = final_sample.sample(frac=1, random_state=random_state).reset_index(drop=True)
            print(f"ğŸ¯ ÄÃ£ láº¥y máº«u: {len(final_sample)} Ä‘iá»ƒm")
        else:
            print("âŒ KhÃ´ng cÃ³ Ä‘á»§ dá»¯ liá»‡u Ä‘á»ƒ táº¡o máº«u")
            return None
    
    # LÆ°u file káº¿t quáº£
    final_sample.to_csv(output_file, index=False)
    print(f"âœ… ÄÃ£ lÆ°u file káº¿t quáº£: {output_file}")
    print(f"ğŸ“ KÃ­ch thÆ°á»›c file: {len(final_sample)} Ä‘iá»ƒm Ã— {len(final_sample.columns)} cá»™t")
    
    # Thá»‘ng kÃª cuá»‘i cÃ¹ng
    print("\nğŸ“ˆ THá»NG KÃŠ Káº¾T QUáº¢:")
    print(f"   - Tá»•ng sá»‘ Ä‘iá»ƒm: {len(final_sample)}")
    print(f"   - Sá»‘ Ä‘áº·c trÆ°ng: {len(available_features)}")
    print(f"   - Äiá»ƒm cÃ³ lÅ©: {final_sample['flood_event'].sum()} ({final_sample['flood_event'].mean()*100:.1f}%)")
    print(f"   - Äiá»ƒm khÃ´ng lÅ©: {len(final_sample) - final_sample['flood_event'].sum()} ({(1-final_sample['flood_event'].mean())*100:.1f}%)")
    print(f"   - CÃ¡c cá»™t trong file: {list(final_sample.columns)}")
    
    return final_sample

# Sá»­ dá»¥ng chÆ°Æ¡ng trÃ¬nh
if __name__ == "__main__":
    input_file = r"C:\Users\Admin\Downloads\prj\BD_PointGrid_10m_aoi_sample.csv"
    output_file = r"C:\Users\Admin\Downloads\filtered_flood_data.csv"
    
    # Lá»c dá»¯ liá»‡u vá»›i 10000 Ä‘iá»ƒm (5000 lÅ©, 5000 khÃ´ng lÅ©)
    result = filter_and_prepare_data(input_file, output_file, sample_size=10000)