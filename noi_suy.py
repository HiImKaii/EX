import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression
import os
import warnings
warnings.filterwarnings('ignore')

class DataCleaner:
    def __init__(self, output_folder="results"):
        """Kh·ªüi t·∫°o b·ªô l√†m s·∫°ch d·ªØ li·ªáu"""
        self.output_folder = output_folder
        self.cleaning_report = {}
        os.makedirs(output_folder, exist_ok=True)
        
    def detect_target_column(self, df):
        """T·ª± ƒë·ªông ph√°t hi·ªán c·ªôt m·ª•c ti√™u nh·ªã ph√¢n (0/1)"""
        binary_cols = []
        
        for col in df.columns:
            unique_vals = df[col].dropna().unique()
            if len(unique_vals) == 2 and set(unique_vals).issubset({0, 1, True, False}):
                binary_cols.append(col)
        
        if binary_cols:
            # ∆Øu ti√™n c·ªôt c√≥ t·ª´ kh√≥a li√™n quan
            keywords = ['flood', 'l≈©', 'event', 'target', 'label', 'class']
            for col in binary_cols:
                if any(keyword in col.lower() for keyword in keywords):
                    return col
            return binary_cols[0]
        
        return None
    
    def remove_outliers_iqr(self, df, multiplier=2.0, target_col=None):
        """Lo·∫°i b·ªè outliers s·ª≠ d·ª•ng IQR method"""
        df_clean = df.copy()
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if target_col and target_col in numeric_cols:
            numeric_cols.remove(target_col)
        
        outlier_counts = {}
        for column in numeric_cols:
            Q1 = df[column].quantile(0.25)
            Q3 = df[column].quantile(0.75)
            IQR = Q3 - Q1
            lower = Q1 - multiplier * IQR
            upper = Q3 + multiplier * IQR
            
            before_count = len(df_clean)
            df_clean = df_clean[(df_clean[column] >= lower) & (df_clean[column] <= upper)]
            outlier_counts[column] = before_count - len(df_clean)
            
        self.cleaning_report['outlier_removal'] = outlier_counts
        return df_clean
    
    def remove_high_correlation(self, df, threshold=0.9, target_col=None):
        """Lo·∫°i b·ªè features c√≥ t∆∞∆°ng quan cao"""
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        if target_col and target_col in numeric_cols:
            feature_cols = [col for col in numeric_cols if col != target_col]
        else:
            feature_cols = numeric_cols
            
        if len(feature_cols) < 2:
            return df
            
        corr_matrix = df[feature_cols].corr().abs()
        upper_triangle = corr_matrix.where(
            np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)
        )
        
        to_drop = [column for column in upper_triangle.columns 
                  if any(upper_triangle[column] > threshold)]
        
        self.cleaning_report['high_correlation'] = to_drop
        
        keep_cols = [col for col in df.columns if col not in to_drop]
        return df[keep_cols]
    
    def select_best_features(self, df, target_col, k=8):
        """Ch·ªçn k features t·ªët nh·∫•t"""
        if not target_col:
            return df
            
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        feature_cols = [col for col in numeric_cols if col != target_col]
        
        if len(feature_cols) <= k:
            return df
            
        X = df[feature_cols]
        y = df[target_col]
        
        selector = SelectKBest(score_func=f_regression, k=k)
        selector.fit(X, y)
        selected_features = [feature_cols[i] for i in selector.get_support(indices=True)]
        
        self.cleaning_report['feature_selection'] = selected_features
        return df[selected_features + [target_col]]
    
    def clean_data(self, df, target_col=None):
        """Quy tr√¨nh l√†m s·∫°ch d·ªØ li·ªáu ch√≠nh"""
        print("üßπ B·∫Øt ƒë·∫ßu l√†m s·∫°ch d·ªØ li·ªáu...")
        print(f"D·ªØ li·ªáu ban ƒë·∫ßu: {df.shape}")
        
        # T·ª± ƒë·ªông ph√°t hi·ªán target column n·∫øu kh√¥ng ƒë∆∞·ª£c cung c·∫•p
        if not target_col:
            target_col = self.detect_target_column(df)
            if target_col:
                print(f"üéØ T·ª± ƒë·ªông ph√°t hi·ªán c·ªôt m·ª•c ti√™u: '{target_col}'")
        
        df_clean = df.copy()
        
        # B∆∞·ªõc 1: X·ª≠ l√Ω missing values
        df_clean = df_clean.dropna()
        print(f"Sau khi x·ª≠ l√Ω missing values: {df_clean.shape}")
        
        # B∆∞·ªõc 2: Lo·∫°i b·ªè duplicates
        df_clean = df_clean.drop_duplicates()
        print(f"Sau khi lo·∫°i b·ªè duplicates: {df_clean.shape}")
        
        # B∆∞·ªõc 3: Lo·∫°i b·ªè outliers
        df_clean = self.remove_outliers_iqr(df_clean, target_col=target_col)
        print(f"Sau khi lo·∫°i b·ªè outliers: {df_clean.shape}")
        
        # B∆∞·ªõc 4: Lo·∫°i b·ªè t∆∞∆°ng quan cao
        df_clean = self.remove_high_correlation(df_clean, target_col=target_col)
        print(f"Sau khi lo·∫°i b·ªè t∆∞∆°ng quan cao: {df_clean.shape}")
        
        # B∆∞·ªõc 5: Feature selection (ch·ªâ khi c√≥ target column)
        if target_col:
            df_clean = self.select_best_features(df_clean, target_col)
            print(f"Sau feature selection: {df_clean.shape}")
        
        return df_clean, target_col
    
    def plot_cleaning_comparison(self, df_original, df_clean, target_col=None):
        """V·∫Ω bi·ªÉu ƒë·ªì so s√°nh tr∆∞·ªõc v√† sau l√†m s·∫°ch"""
        print("üìä ƒêang v·∫Ω bi·ªÉu ƒë·ªì so s√°nh...")
        
        numeric_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()
        if target_col and target_col in numeric_cols:
            feature_cols = [col for col in numeric_cols if col != target_col]
        else:
            feature_cols = numeric_cols
            
        plot_cols = feature_cols[:4]  # Ch·ªâ v·∫Ω 4 c·ªôt ƒë·∫ßu
        
        if len(plot_cols) == 0:
            print("‚ö†Ô∏è Kh√¥ng c√≥ c·ªôt s·ªë ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì")
            return
        
        fig, axes = plt.subplots(2, len(plot_cols), figsize=(4*len(plot_cols), 8))
        if len(plot_cols) == 1:
            axes = axes.reshape(-1, 1)
        
        for i, col in enumerate(plot_cols):
            # Histogram so s√°nh
            axes[0, i].hist(df_original[col], bins=30, alpha=0.6, label='Tr∆∞·ªõc', color='#e74c3c')
            axes[0, i].hist(df_clean[col], bins=30, alpha=0.6, label='Sau', color='#2ecc71')
            axes[0, i].set_title(f'{col} - Ph√¢n b·ªë')
            axes[0, i].legend()
            axes[0, i].grid(True, alpha=0.3)
            
            # Boxplot so s√°nh
            data_to_plot = [df_original[col].dropna(), df_clean[col].dropna()]
            axes[1, i].boxplot(data_to_plot, labels=['Tr∆∞·ªõc', 'Sau'])
            axes[1, i].set_title(f'{col} - Boxplot')
            axes[1, i].grid(True, alpha=0.3)
        
        plt.suptitle('So s√°nh D·ªØ li·ªáu: Tr∆∞·ªõc v√† Sau L√†m s·∫°ch', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(f'{self.output_folder}/cleaning_comparison.png', dpi=300, bbox_inches='tight')
        plt.show()

class DataAnalyzer:
    def __init__(self, output_folder="results"):
        """Kh·ªüi t·∫°o b·ªô ph√¢n t√≠ch d·ªØ li·ªáu"""
        self.output_folder = output_folder
        self.df = None
        self.target_col = None
        self.numeric_cols = []
        os.makedirs(output_folder, exist_ok=True)
        
    def load_data(self, data_source):
        """T·∫£i d·ªØ li·ªáu t·ª´ file ho·∫∑c DataFrame"""
        if isinstance(data_source, str):
            print("üìä ƒêang t·∫£i d·ªØ li·ªáu t·ª´ file...")
            self.df = pd.read_csv(data_source)
        elif isinstance(data_source, pd.DataFrame):
            print("üìä ƒêang t·∫£i d·ªØ li·ªáu t·ª´ DataFrame...")
            self.df = data_source.copy()
        else:
            raise ValueError("Data source ph·∫£i l√† ƒë∆∞·ªùng d·∫´n file ho·∫∑c DataFrame")
            
        print(f"T·∫£i th√†nh c√¥ng: {len(self.df)} d√≤ng, {len(self.df.columns)} c·ªôt")
        
    def detect_target_column(self):
        """T·ª± ƒë·ªông ph√°t hi·ªán c·ªôt m·ª•c ti√™u nh·ªã ph√¢n"""
        binary_cols = []
        
        for col in self.df.columns:
            unique_vals = self.df[col].dropna().unique()
            if len(unique_vals) == 2 and set(unique_vals).issubset({0, 1, True, False}):
                binary_cols.append(col)
        
        if binary_cols:
            # ∆Øu ti√™n c·ªôt c√≥ t·ª´ kh√≥a li√™n quan
            keywords = ['flood', 'l≈©', 'event', 'target', 'label', 'class']
            for col in binary_cols:
                if any(keyword in col.lower() for keyword in keywords):
                    self.target_col = col
                    break
            
            if not self.target_col:
                self.target_col = binary_cols[0]
                
            print(f"üéØ Ph√°t hi·ªán c·ªôt m·ª•c ti√™u: '{self.target_col}'")
        else:
            print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y c·ªôt m·ª•c ti√™u nh·ªã ph√¢n")
            
    def identify_columns(self):
        """Ph√¢n lo·∫°i c√°c c·ªôt s·ªë"""
        self.numeric_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()
        
        if self.target_col and self.target_col in self.numeric_cols:
            self.numeric_cols.remove(self.target_col)
            
        print(f"üìã T√¨m th·∫•y {len(self.numeric_cols)} c·ªôt s·ªë ƒë·ªÉ ph√¢n t√≠ch")
        
    def plot_correlation_matrix(self):
        """V·∫Ω ma tr·∫≠n t∆∞∆°ng quan (n·ª≠a d∆∞·ªõi)"""
        if len(self.numeric_cols) < 2:
            print("‚ö†Ô∏è Kh√¥ng ƒë·ªß c·ªôt s·ªë ƒë·ªÉ v·∫Ω ma tr·∫≠n t∆∞∆°ng quan")
            return
            
        print("üîó ƒêang v·∫Ω ma tr·∫≠n t∆∞∆°ng quan...")
        
        corr_matrix = self.df[self.numeric_cols].corr()
        mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
        
        plt.figure(figsize=(12, 10))
        sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='RdBu_r', 
                   center=0, fmt='.2f', square=True, linewidths=0.5)
        plt.title('Ma tr·∫≠n T∆∞∆°ng quan', fontsize=14, fontweight='bold')
        plt.tight_layout()
        plt.savefig(f'{self.output_folder}/correlation_matrix.png', dpi=300, bbox_inches='tight')
        plt.show()
        
    def plot_pairplot(self):
        """V·∫Ω ma tr·∫≠n m·∫≠t ƒë·ªô x√°c su·∫•t"""
        if len(self.numeric_cols) < 2:
            print("‚ö†Ô∏è Kh√¥ng ƒë·ªß c·ªôt s·ªë ƒë·ªÉ v·∫Ω pairplot")
            return
            
        print("üìä ƒêang v·∫Ω ma tr·∫≠n m·∫≠t ƒë·ªô x√°c su·∫•t...")
        
        # Ch·ªçn t·ªëi ƒëa 6 c·ªôt ƒë·ªÉ tr√°nh bi·ªÉu ƒë·ªì qu√° ph·ª©c t·∫°p
        cols_to_plot = self.numeric_cols[:6]
        plot_data = cols_to_plot.copy()
        
        if self.target_col:
            plot_data.append(self.target_col)
            
        g = sns.pairplot(
            data=self.df[plot_data],
            hue=self.target_col if self.target_col else None,
            diag_kind='kde',
            plot_kws={'alpha': 0.7, 's': 8, 'edgecolors': 'none'},
            diag_kws={'fill': True, 'alpha': 0.8, 'linewidth': 1.5},
            height=2,
            aspect=1,
            corner=True,
            palette=['#e74c3c', '#2ecc71'] if self.target_col else None
        )
        
        g.fig.suptitle('Ma tr·∫≠n M·∫≠t ƒë·ªô X√°c su·∫•t', fontsize=16, y=1.02, fontweight='bold')
        
        if self.target_col and g._legend:
            g._legend.set_title('Ph√¢n lo·∫°i', prop={'size': 12, 'weight': 'bold'})
            legend_labels = ['Nh√≥m 0', 'Nh√≥m 1']
            for t, l in zip(g._legend.texts, legend_labels):
                t.set_text(l)
                
        plt.tight_layout()
        plt.savefig(f'{self.output_folder}/pairplot_density.png', dpi=300, bbox_inches='tight')
        plt.show()
        
    def plot_target_correlations(self):
        """V·∫Ω t∆∞∆°ng quan v·ªõi c·ªôt m·ª•c ti√™u"""
        if not self.target_col or len(self.numeric_cols) == 0:
            print("‚ö†Ô∏è Kh√¥ng th·ªÉ v·∫Ω t∆∞∆°ng quan v·ªõi c·ªôt m·ª•c ti√™u")
            return
            
        print("üìà ƒêang v·∫Ω t∆∞∆°ng quan v·ªõi c·ªôt m·ª•c ti√™u...")
        
        target_corr = self.df[self.numeric_cols].corrwith(self.df[self.target_col])
        target_corr = target_corr.sort_values(key=abs, ascending=True)
        
        plt.figure(figsize=(10, max(6, len(target_corr) * 0.4)))
        colors = ['#e74c3c' if x < 0 else '#2ecc71' for x in target_corr.values]
        target_corr.plot(kind='barh', color=colors)
        plt.title(f'T∆∞∆°ng quan v·ªõi "{self.target_col}"', fontsize=14, fontweight='bold')
        plt.xlabel('H·ªá s·ªë t∆∞∆°ng quan')
        plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)
        plt.tight_layout()
        plt.savefig(f'{self.output_folder}/target_correlations.png', dpi=300, bbox_inches='tight')
        plt.show()

class IntegratedDataPipeline:
    def __init__(self, output_folder="results"):
        """Pipeline t√≠ch h·ª£p l√†m s·∫°ch v√† ph√¢n t√≠ch d·ªØ li·ªáu"""
        self.output_folder = output_folder
        self.cleaner = DataCleaner(output_folder)
        self.analyzer = DataAnalyzer(output_folder)
        
    def run_cleaning(self, file_path, save_cleaned=True):
        """Ch·∫°y quy tr√¨nh l√†m s·∫°ch d·ªØ li·ªáu"""
        print("=" * 60)
        print("üßπ B∆Ø·ªöC 1: L√ÄM S·∫†CH D·ªÆ LI·ªÜU")
        print("=" * 60)
        
        # T·∫£i d·ªØ li·ªáu g·ªëc
        df_original = pd.read_csv(file_path)
        print(f"üìä D·ªØ li·ªáu g·ªëc: {df_original.shape}")
        
        # T·ª± ƒë·ªông ph√°t hi·ªán target column
        target_col = self.cleaner.detect_target_column(df_original)
        
        # L√†m s·∫°ch d·ªØ li·ªáu
        df_cleaned, target_col = self.cleaner.clean_data(df_original, target_col)
        
        # V·∫Ω bi·ªÉu ƒë·ªì so s√°nh
        self.cleaner.plot_cleaning_comparison(df_original, df_cleaned, target_col)
        
        # L∆∞u d·ªØ li·ªáu ƒë√£ l√†m s·∫°ch
        if save_cleaned:
            cleaned_path = file_path.replace('.csv', '_cleaned.csv')
            df_cleaned.to_csv(cleaned_path, index=False)
            print(f"üíæ D·ªØ li·ªáu ƒë√£ l√†m s·∫°ch ƒë∆∞·ª£c l∆∞u: {cleaned_path}")
            
        return df_cleaned, target_col, cleaned_path if save_cleaned else None
        
    def run_analysis(self, data_source):
        """Ch·∫°y quy tr√¨nh ph√¢n t√≠ch d·ªØ li·ªáu"""
        print("\n" + "=" * 60)
        print("üìä B∆Ø·ªöC 2: PH√ÇN T√çCH D·ªÆ LI·ªÜU")
        print("=" * 60)
        
        # T·∫£i d·ªØ li·ªáu
        self.analyzer.load_data(data_source)
        self.analyzer.detect_target_column()
        self.analyzer.identify_columns()
        
        # V·∫Ω c√°c bi·ªÉu ƒë·ªì ph√¢n t√≠ch
        self.analyzer.plot_correlation_matrix()
        self.analyzer.plot_pairplot()
        self.analyzer.plot_target_correlations()
        
        # T·∫°o b√°o c√°o t√≥m t·∫Øt
        self.generate_summary()
        
    def generate_summary(self):
        """T·∫°o b√°o c√°o t√≥m t·∫Øt t·ªïng h·ª£p"""
        print("\n" + "=" * 60)
        print("üìã B√ÅO C√ÅO T√ìM T·∫ÆT")
        print("=" * 60)
        
        # Th√¥ng tin c∆° b·∫£n
        print(f"üìä T·ªïng s·ªë d√≤ng: {len(self.analyzer.df)}")
        print(f"üìä T·ªïng s·ªë c·ªôt: {len(self.analyzer.df.columns)}")
        print(f"üìä S·ªë c·ªôt s·ªë: {len(self.analyzer.numeric_cols)}")
        print(f"üéØ C·ªôt m·ª•c ti√™u: {self.analyzer.target_col or 'Kh√¥ng ph√°t hi·ªán'}")
        
        if self.analyzer.target_col:
            target_rate = self.analyzer.df[self.analyzer.target_col].mean()
            print(f"üìà T·ª∑ l·ªá nh√≥m 1: {target_rate:.1%}")
            
        # B√°o c√°o l√†m s·∫°ch
        if hasattr(self.cleaner, 'cleaning_report') and self.cleaner.cleaning_report:
            print("\nüßπ Chi ti·∫øt l√†m s·∫°ch:")
            for step, details in self.cleaner.cleaning_report.items():
                if step == 'outlier_removal':
                    total_outliers = sum(details.values()) if isinstance(details, dict) else 0
                    print(f"  - Outliers lo·∫°i b·ªè: {total_outliers}")
                elif step == 'high_correlation':
                    removed_count = len(details) if isinstance(details, list) else 0
                    print(f"  - Features t∆∞∆°ng quan cao: {removed_count}")
                elif step == 'feature_selection':
                    selected_count = len(details) if isinstance(details, list) else 0
                    print(f"  - Features ƒë∆∞·ª£c ch·ªçn: {selected_count}")
        
        print("=" * 60)
        print(f"üìÅ T·∫•t c·∫£ k·∫øt qu·∫£ ƒë∆∞·ª£c l∆∞u t·∫°i: {self.output_folder}")
        
    def run_full_pipeline(self, file_path):
        """Ch·∫°y to√†n b·ªô pipeline: l√†m s·∫°ch -> ph√¢n t√≠ch"""
        try:
            # B∆∞·ªõc 1: L√†m s·∫°ch d·ªØ li·ªáu
            df_cleaned, target_col, cleaned_path = self.run_cleaning(file_path)
            
            # B∆∞·ªõc 2: Ph√¢n t√≠ch d·ªØ li·ªáu ƒë√£ l√†m s·∫°ch
            self.run_analysis(df_cleaned)
            
            print("\nüéâ PIPELINE HO√ÄN TH√ÄNH!")
            return df_cleaned, target_col
            
        except Exception as e:
            print(f"‚ùå L·ªói trong pipeline: {e}")
            return None, None

# H√†m ti·ªán √≠ch
def clean_data(file_path, output_folder="results"):
    """Ch·ªâ l√†m s·∫°ch d·ªØ li·ªáu"""
    cleaner = DataCleaner(output_folder)
    df = pd.read_csv(file_path)
    df_cleaned, target_col = cleaner.clean_data(df)
    
    # L∆∞u k·∫øt qu·∫£
    cleaned_path = file_path.replace('.csv', '_cleaned.csv')
    df_cleaned.to_csv(cleaned_path, index=False)
    
    return df_cleaned, cleaned_path

def analyze_data(data_source, output_folder="results"):
    """Ch·ªâ ph√¢n t√≠ch d·ªØ li·ªáu"""
    analyzer = DataAnalyzer(output_folder)
    analyzer.load_data(data_source)
    analyzer.detect_target_column()
    analyzer.identify_columns()
    analyzer.plot_correlation_matrix()
    analyzer.plot_pairplot()
    analyzer.plot_target_correlations()
    return analyzer

def full_pipeline(file_path, output_folder="results"):
    """Ch·∫°y to√†n b·ªô pipeline"""
    pipeline = IntegratedDataPipeline(output_folder)
    return pipeline.run_full_pipeline(file_path)

# Ch·∫°y ch∆∞∆°ng tr√¨nh
if __name__ == "__main__":
    # Thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n file theo nhu c·∫ßu
    file_path = "data.csv"
    
    # Ch·ªçn ch·∫ø ƒë·ªô ch·∫°y:
    # 1. Ch·ªâ l√†m s·∫°ch
    # df_cleaned, cleaned_path = clean_data(file_path)
    
    # 2. Ch·ªâ ph√¢n t√≠ch (v·ªõi d·ªØ li·ªáu ƒë√£ s·∫°ch)
    # analyzer = analyze_data("data_cleaned.csv")
    
    # 3. Ch·∫°y to√†n b·ªô pipeline
    df_result, target_col = full_pipeline(file_path)